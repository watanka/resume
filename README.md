### AOS 알파 - 애자일소다 딥러닝 사이언티스트 인턴 (2019.08 - 2020.02)
#### 프로젝트 개요 및 담당 역할
AOS 알파는 사고 차량 이미지를 기반으로 사고견적 비용을 예측하는 딥러닝 프로젝트입니다. 비용 예측 프로세스는 인풋 이미지를 견적판별 가능 여부, 파손부위 포착, 파손 정도 판별 순으로 이루어집니다. 저는 이 프로젝트에서 머신러닝 엔지니어 인턴으로 참여하여 인풋 이미지에 대한 견적판별 가능 여부를 판단하는 이미지 분류 모델 개발 및 서빙을 담당하였습니다. 이 프로젝트는 Nvidia GPU Technology Conference GTC 2020 비즈니스 영역 딥러닝 활용 성공사례로 소개된 바 있습니다.
#### 기술 스택 및 개발 상세 내용
기술 스택
- 모델 개발: python, tensorflow, keras
- 모델 서빙: Flask, Tensorflow Serving

##### 불균형한 이미지셋 학습
AOS 알파 앱은 모바일로 손상된 차량 이미지를 송신받으면, 해당 이미지가 사고견적 비용 판별 가능 대상인지 분류해주어야합니다. 견적 판별이 불가능한 이미지는 카메라 초점이 흐릿한 경우, 차량의 일부분만 찍힌 경우, 차량 손상이 너무 심한 경우, 차량 사진이 아닌 경우(실수로 차대번호나 주민등록증 등 손해보험 청구에 필요한 다른 이미지가 들어온 경우)가 있습니다. 견적판별 가능 여부를 판단하는 이 프로세스에서 가장 큰 문제점은 견적판별 가능 대상 이미지는 확실한 반면, 견적판별 불가능 대상은 다양하고, 학습에 적용가능한 이미지 장수가 적다는 것이였습니다.
이 문제를 해결하기 위해 첫번째 시도한 방법은 데이터 증강이였습니다. 이미지 초점을 흐릿하게 하거나, 임의로 축소 또는 확대하여 견적 판별 불가능 이미지 수량을 증가시켰습니다. 또한, 웹 크롤링을 통해 필요한 이미지들을 보충하였습니다. 두번째 방법은 메타 러닝이였습니다. 이미지에 대한 피쳐들을 추출하고 학습하여, 견적판별 가능 이미지들은 클러스터에 포함되고, 불가능 이미지들은 클러스터로부터 거리가 멀 수 있도록 모델을 선정하고 학습을 진행했습니다. 결과적으로 고객사인 보험개발원에서 제공한 테스트 이미지 500장을 기준으로 93% 이상의 성능을 달성할 수 있었습니다.

##### 데이터 라벨링 소요 시간 개선
모델 학습에 필요한 데이터 라벨링을 진행하는 일은 딥러닝 프로젝트에서 굉장히 중요하지만, 시간과 노동력이 많이 필요한 작업입니다. 이미지 분류 시 수기로 이미지들을 폴더에 분류하던 작업에 걸리는 시간을 줄이기 위해, UI를 만들어 버튼클릭만으로 폴더에 분류될 수 있도록 라벨링 툴을 개발하였습니다. 그리고, 1차적으로 딥러닝 모델이 학습되었을 때, 라벨링이 필요한 추가 이미지들에 대해 모델을 태워 분류를 진행했습니다. 몇몇 틀린 결과에 대한 검증만 수행하면 되었기 때문에, 처음부터 분류를 진행하는 것보다 라벨링 시간을 훨씬 단축할 수 있었습니다.


### 애자일소다 알고리즘팀 소속 컴퓨터비전 업무 담당(2020.08 - 2023.1)
- 컴퓨터 비전 관련 PoC 수행 
- PDF 정보 추출 모듈
- 합성 문서 생성 모듈 개발
- 차량 번호판 인식 프로젝트
- 장애물 인식 프로젝트
- 
### TwinReader - 애자일소다 - (2020.08 - 2023.1)
#### 프로젝트 개요 및 담당 역할
트윈리더는 범용 문서 이미지에 대해 글자를 인식하고, 파싱한 정보를 구조화해주는 OCR 서비스입니다. B2B 서비스로 일 6만 건 정도의 문서(보험청구서, 진료비 영수증 등)를 처리해야하는 보험사에 제공하였습니다. 그리고 고객사의 폐쇄망 환경에 서비스를 설치 및 운영하는 업무를 담당하였습니다. 
OCR 프로세스는 보통 이미지 내에 글자 영역을 탐지하는 '글자탐지' 단계와 탐지한 영역 내의 글자를 인식하는 '글자인식' 단계로 나뉩니다.(OCR에 대한 좀 더 자세한 설명은 제 블로그 글에 정리해두었습니다[링크](https://watanka.github.io/ocr%EC%9D%B4%EB%9E%80)) 글자탐지 모델은 OCR 프로세스의 첫번째 단계로, 탐지 결과가 OCR 최종결과에 영향을 많이 미칩니다. 만약 탐지해야하는 글자를 탐지하지 못 했을 경우, 다음 프로세스의 성능이 아무리 좋아도 결과가 나올 수 없습니다. 또, 만약 하나의 단어로 탐지해야하는 영역이 나눠지거나 다른 영역과 합쳐져서 나오는 경우, 최종 결과에 대한 추가적인 후처리가 필요하게 됩니다. 예를 들어, '금액: 10030원' 부분을 '금액: 100'과 '30원'으로 나눠 탐지하게 된다면, 글자탐지 결과로써의 오차는 그리 크지 않지만, 최종 정보로써의 오차는 굉장히 큽니다. 팀은 각 프로세스(전처리, STD, STR, 후처리 등)를 나눠서 팀원들이 각각의 독립적인 모델을 개발하는 식으로 구성되어있었는데, 저는 글자탐지 모델 담당이었지만 글자탐지뿐만 아니라 OCR 최종 결과를 개선하기 위해 담당 영역을 가리지 않고 작업하였습니다.

#### 기술 스택 및 개발 상세 내용
기술 스택
모델 개발: Python, Pytorch, TensorFlow, WandB
모델 서빙: Flask, FastAPI, Docker, TensorRT, ONNX, Nvidia Triton Server

##### 모델 실험 환경 개선
더 좋은 성능을 내기 위해 모델들의 여러 조합을 실험해보고 결과를 확인하는 작업이 필요했습니다. 각 프로세스의 모델 조합, 모델 종류, 하이퍼 파라미터, 학습 데이터, 그리고 평가 데이터에 따라 다양한 조합이 나올 수 있기 때문에 반복적인 실험이 필수였습니다. 하지만, 팀에서 각자 담당하는 모델이 다르고, 모델에 따라 개발 환경이 다르기 때문에 실험을 하는 과정이 오래 걸리는 경우가 많이 발생했습니다. 이런 문제를 해결하기 위해, 실험 환경, 각 모델의 인풋 아웃풋 형식, 모델 패키징 규격을 통일하였습니다. 실험 환경은 도커로 통일하고, 전처리와 후처리는 대략 비슷한 요소들이 많기 때문에 재사용이 가능한 모듈을 두어 개발시간을 단축하였습니다. 그리고 각 모델의 인풋, 아웃풋 형식을 정해 모델이 바뀌어도 동작할 수 있도록 하였습니다. 글자탐지 모델의 인풋 형식은 문서 이미지, 아웃풋 형식은 박스 좌표, 그리고 글자인식 모델의 인풋 형식은 문자영역 이미지, 그리고 아웃풋 형식은 텍스트 형식으로 규정하였습니다. 글자탐지 결과의 박스 형식이나  글자인식 결과의 인코딩 텍스트 형식 같은 경우, 모델마다 다른 포맷들이 존재하는데, 이런 부분은 yaml에 명시적으로 정의함으로써 실수로 생길 수 있는 문제를 처리했습니다. 그리고, 모델 추론은 ONNX runtime, TensorRT를 활용하여 API화하였습니다. 결과적으로 개발환경을 통일하고 OCR 프로세스를 추상화하여 처리함으로써 실험에 반복적으로 발생하는 셋팅 시간을 단축하였습니다. 

##### 모델 서빙 최적화
좋은 모델을 만드는 것 또한 중요하지만, 실제 서빙되는 모델이 빠르고 정확하게 동작하는 것도 중요합니다. 운영되는 모델 서빙을 최적화하기 위해, NVIDIA Trition Inference Server를 도입하여 서빙 성능을 개선하였습니다. STD와 STR은 순차적인 프로세스이긴 하지만, 인풋값의 출처만 확인할 수 있다면(한 이미지에서 나오는 여러 STD 결과), 독립적으로 분리될 수 있는 프로세스입니다. Kafka 메세지 큐를 사용하여, STR 프로세스가 STD 결과에 의존하지 않도록 비동기 파이프라인을 구성하였습니다. STR 결과의 배치 사이즈를 GPU 사양에 맞게 최적화할 수 있게 되었고, throughput을 2배 이상 개선할 수 있었습니다.


### PetFins 서비스 개발 - 머신러닝 엔지니어 - (2024.02 - 2024.08)
#### 프로젝트 개요 및 담당 역할
[[link](https://github.com/watanka/petcare-cost-prediction)]
펫핀스는 반려동물 보험 웹서비스입니다. 등록된 반려동물 건강정보를 기반으로 평균 보험료를 예측 제공함으로써 사용자에게 보험 가입시 절약할 수 있는 금액을 알려주는 예측 서비스 개발을 담당하였습니다. 예측 서비스 기획 단계부터 머신러닝 모델 개발, 그리고 백엔드 개발을 담당하였습니다.

#### 기술 스택 및 개발 상세 내용
- 모델 개발: Python, LightGBM, Sklearn, Mlflow, Streamlit
- 백엔드: 네이버 클라우드 플랫폼, Docker, MySQL, Docker-compose
- 모델 운영: FastAPI, Nginx 

##### 머신러닝 모델 재학습 파이프라인 구성


## 사이드 프로젝트
### Muze

### Ticketeer - (2024.06 - 2024.08)
#### 프로젝트 개요
[[link](https://github.com/watanka/concert-ticketing)]
티켓티어는 콘서트 티켓 예매용 프로젝트입니다. 짧은 시간에 티켓 예매를 위해 몰린 트래픽 상황을 가정하고 진행하였습니다.

#### 기술스택 및 개발 상세 내용
기술 스택
- Java, SpringBoot, MySQL, Redis, Spring Data JPA, JUnit, Mockito, Docker, AWS

##### 아키텍쳐
구현한 기능: 
- 콘서트 및 콘서트 좌석 조회
- 콘서트 좌석예약
- 포인트 충전/조회
- 결제내역 조회

##### 동시성 처리를 통한 데이터 정합성 보장

##### 대기열 구성을 통한 트래픽 처리


## 대외활동
### 개발자 글쓰기 모임 글또
## 자격증
CKA(Certified Kubernetes Administrator) 2024.09
SQLD - 2024.09
AWS Cloud Practitioner - 2024.06
빅데이터 분석 기사 2022.12
## 프로젝트 이름
### 프로젝트 개요
### 프로젝트 소개 및 주요 기능
#### 기술 스택 및 개발 상세 내용
어떤 문제를 해결했는가?
어떤 부분에서 기여했는가



트윈리더
- 여러 문서 유형(보험 청구서, 진료비 영수증, 견적서)에 대한 OCR 성능을 개선하는 업무 담당
- Scene Text Detection 모델 실험 및 개발
- OCR 서비스 개발
- 온프레미스 환경(폐쇄망)에 서비스 배포
더 빠르고 성능 좋은 STD 모델 개발
데이터 품질, 수량 추가 확보
모델 학습 실험 환경 개선
OCR 파싱 정보 계층화 시도
