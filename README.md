AOS 알파 - 애자일소다 딥러닝 사이언티스트 인턴 (2019.08 - 2020.02)
프로젝트 개요 및 담당 역할
AOS 알파는 사고 차량 이미지를 기반으로 사고견적 비용을 예측하는 딥러닝 프로젝트입니다. 비용 예측 프로세스는 인풋 이미지를 견적판별 가능 여부, 파손부위 포착, 파손 정도 판별 순으로 이루어집니다. 저는 이 프로젝트에서 머신러닝 엔지니어 인턴으로 참여하여 인풋 이미지에 대한 견적판별 가능 여부를 판단하는 이미지 분류 모델 개발 및 서빙을 담당하였습니다. 이 프로젝트는 Nvidia GPU Technology Conference GTC 2020 비즈니스 영역 딥러닝 활용 성공사례로 소개된 바 있습니다.

기술 스택 및 개발 상세 내용
기술 스택

모델 개발: python, tensorflow, keras
모델 서빙: Flask, Tensorflow Serving
불균형한 이미지셋 학습
AOS 알파 앱은 모바일로 손상된 차량 이미지를 송신받으면, 해당 이미지가 사고견적 비용 판별 가능 대상인지 분류해주어야합니다. 견적 판별이 불가능한 이미지는 카메라 초점이 흐릿한 경우, 차량의 일부분만 찍힌 경우, 차량 손상이 너무 심한 경우, 차량 사진이 아닌 경우(실수로 차대번호나 주민등록증 등 손해보험 청구에 필요한 다른 이미지가 들어온 경우)가 있습니다. 견적판별 가능 여부를 판단하는 이 프로세스에서 가장 큰 문제점은 견적판별 가능 대상 이미지는 확실한 반면, 견적판별 불가능 대상은 다양하고, 학습에 적용가능한 이미지 장수가 적다는 것이였습니다. 이 문제를 해결하기 위해 첫번째 시도한 방법은 데이터 증강이였습니다. 이미지 초점을 흐릿하게 하거나, 임의로 축소 또는 확대하여 견적 판별 불가능 이미지 수량을 증가시켰습니다. 또한, 웹 크롤링을 통해 필요한 이미지들을 보충하였습니다. 두번째 방법은 메타 러닝이였습니다. 이미지에 대한 피쳐들을 추출하고 학습하여, 견적판별 가능 이미지들은 클러스터에 포함되고, 불가능 이미지들은 클러스터로부터 거리가 멀 수 있도록 모델을 선정하고 학습을 진행했습니다. 결과적으로 고객사인 보험개발원에서 제공한 테스트 이미지 500장을 기준으로 93% 이상의 성능을 달성할 수 있었습니다.

데이터 라벨링 소요 시간 개선
모델 학습에 필요한 데이터 라벨링을 진행하는 일은 딥러닝 프로젝트에서 굉장히 중요하지만, 시간과 노동력이 많이 필요한 작업입니다. 이미지 분류 시 수기로 이미지들을 폴더에 분류하던 작업에 걸리는 시간을 줄이기 위해, UI를 만들어 버튼클릭만으로 폴더에 분류될 수 있도록 라벨링 툴을 개발하였습니다. 그리고, 1차적으로 딥러닝 모델이 학습되었을 때, 라벨링이 필요한 추가 이미지들에 대해 모델을 태워 분류를 진행했습니다. 몇몇 틀린 결과에 대한 검증만 수행하면 되었기 때문에, 처음부터 분류를 진행하는 것보다 라벨링 시간을 훨씬 단축할 수 있었습니다.

애자일소다 알고리즘팀 소속 컴퓨터비전 업무 담당(2020.08 - 2023.1)
컴퓨터 비전 관련 PoC 수행
PDF 정보 추출 모듈
합성 문서 생성 모듈 개발
차량 번호판 인식 프로젝트
장애물 인식 프로젝트
TwinReader - 애자일소다 - (2020.08 - 2023.1)
프로젝트 개요 및 담당 역할
트윈리더는 범용 문서 이미지에 대해 글자를 인식하고, 파싱한 정보를 구조화해주는 OCR 서비스입니다. B2B 서비스로 일 6만 건 정도의 문서(보험청구서, 진료비 영수증 등)를 처리해야하는 보험사에 제공하였습니다. 그리고 고객사의 폐쇄망 환경에 서비스를 설치 및 운영하는 업무를 담당하였습니다. OCR 프로세스는 보통 이미지 내에 글자 영역을 탐지하는 '글자탐지' 단계와 탐지한 영역 내의 글자를 인식하는 '글자인식' 단계로 나뉩니다.(OCR에 대한 좀 더 자세한 설명은 제 블로그 글에 정리해두었습니다링크) 글자탐지 모델은 OCR 프로세스의 첫번째 단계로, 탐지 결과가 OCR 최종결과에 영향을 많이 미칩니다. 만약 탐지해야하는 글자를 탐지하지 못 했을 경우, 다음 프로세스의 성능이 아무리 좋아도 결과가 나올 수 없습니다. 또, 만약 하나의 단어로 탐지해야하는 영역이 나눠지거나 다른 영역과 합쳐져서 나오는 경우, 최종 결과에 대한 추가적인 후처리가 필요하게 됩니다. 예를 들어, '금액: 10030원' 부분을 '금액: 100'과 '30원'으로 나눠 탐지하게 된다면, 글자탐지 결과로써의 오차는 그리 크지 않지만, 최종 정보로써의 오차는 굉장히 큽니다. 팀은 각 프로세스(전처리, STD, STR, 후처리 등)를 나눠서 팀원들이 각각의 독립적인 모델을 개발하는 식으로 구성되어있었는데, 저는 글자탐지 모델 담당이었지만 글자탐지뿐만 아니라 OCR 최종 결과를 개선하기 위해 담당 영역을 가리지 않고 작업하였습니다.

기술 스택 및 개발 상세 내용
기술 스택 모델 개발: Python, Pytorch, TensorFlow, WandB 
모델 서빙: Flask, FastAPI, Docker, TensorRT, ONNX, Nvidia Triton Server

모델 실험 환경 개선
더 좋은 성능을 내기 위해 모델들의 여러 조합을 실험해보고 결과를 확인하는 작업이 필요했습니다. 각 프로세스의 모델 조합, 모델 종류, 하이퍼 파라미터, 학습 데이터, 그리고 평가 데이터에 따라 다양한 조합이 나올 수 있기 때문에 반복적인 실험이 필수였습니다. 하지만, 팀에서 각자 담당하는 모델이 다르고, 모델에 따라 개발 환경이 다르기 때문에 실험을 하는 과정이 오래 걸리는 경우가 많이 발생했습니다. 이런 문제를 해결하기 위해, 실험 환경, 각 모델의 인풋 아웃풋 형식, 모델 패키징 규격을 통일하였습니다. 실험 환경은 도커로 통일하고, 전처리와 후처리는 대략 비슷한 요소들이 많기 때문에 재사용이 가능한 모듈을 두어 개발시간을 단축하였습니다. 그리고 각 모델의 인풋, 아웃풋 형식을 정해 모델이 바뀌어도 동작할 수 있도록 하였습니다. 글자탐지 모델의 인풋 형식은 문서 이미지, 아웃풋 형식은 박스 좌표, 그리고 글자인식 모델의 인풋 형식은 문자영역 이미지, 그리고 아웃풋 형식은 텍스트 형식으로 규정하였습니다. 글자탐지 결과의 박스 형식이나 글자인식 결과의 인코딩 텍스트 형식 같은 경우, 모델마다 다른 포맷들이 존재하는데, 이런 부분은 yaml에 명시적으로 정의함으로써 실수로 생길 수 있는 문제를 처리했습니다. 그리고, 모델 추론은 ONNX runtime, TensorRT를 활용하여 API화하였습니다. 결과적으로 개발환경을 통일하고 OCR 프로세스를 추상화하여 처리함으로써 실험에 반복적으로 발생하는 셋팅 시간을 단축하였습니다.

모델 서빙 최적화
좋은 모델을 만드는 것 또한 중요하지만, 실제 서빙되는 모델이 빠르고 정확하게 동작하는 것도 중요합니다. 운영되는 모델 서빙을 최적화하기 위해, NVIDIA Trition Inference Server를 도입하여 서빙 성능을 개선하였습니다. STD와 STR은 순차적인 프로세스이긴 하지만, 인풋값의 출처만 확인할 수 있다면(한 이미지에서 나오는 여러 STD 결과), 독립적으로 분리될 수 있는 프로세스입니다. Kafka 메세지 큐를 사용하여, STR 프로세스가 STD 결과에 의존하지 않도록 비동기 파이프라인을 구성하였습니다. STR 결과의 배치 사이즈를 GPU 사양에 맞게 최적화할 수 있게 되었고, throughput을 2배 이상 개선할 수 있었습니다.

PetFins 서비스 개발 - 머신러닝 엔지니어 - (2024.02 - 2024.08)
프로젝트 개요 및 담당 역할
[link](https://petfins.net/newbreeddiscriminator) 펫핀스는 반려동물 보험 웹서비스입니다. 등록된 반려동물 건강정보를 기반으로 평균 보험료를 예측 제공함으로써 사용자에게 보험 가입시 절약할 수 있는 금액을 알려주는 예측 서비스 개발을 담당하였습니다. 예측 서비스 기획 단계부터 머신러닝 모델 개발, 그리고 백엔드 개발을 담당하였습니다.

기술 스택 및 개발 상세 내용
모델 개발: Python, LightGBM, Sklearn, Mlflow, Streamlit
백엔드: 네이버 클라우드 플랫폼, Docker, MySQL, Docker-compose
모델 운영: FastAPI, Nginx

### 머신러닝 모델 재학습 파이프라인 구성
반려동물 치료비는 정책이 통일되어있지 않아 동물 병원마다 금액이 다른 경우가 많습니다. 그래서 운영 중인 서비스에 추가되는 데이터에 대해 재학습이 가능하도록 파이프라인을 설계하였습니다. 모델 변경될 수 있는 상황을 고려하여 추상 클래스를 작성하였습니다.
데이터베이스를 모니터링하는 프로세스를 두어 예측 결과가 몇 퍼센트 이상 벗어나는 데이터가 일정량 추가될 경우, 자동으로 재학습이 트리거될 수 있도록 구성하였습니다.
학습 완료 시, MLflow 서버를 두어 새로 학습된 모델의 기존 데이터 추론 결과를 확인할 수 있도록 하였습니다. 
그리고, 새로운 모델을 선택하고 배포할 때, 운영 서비스의 다운타임이 최소화될 수 있도록 nginx와 github action으로 롤링 업데이트를 구현하였습니다.



사이드 프로젝트

Muze - (2024.10 - )
프로젝트 개요
[link](https://github.com/watanka/muze)
뮤즈는 음악 취향을 공유할 수 있는 SNS 앱입니다. 

기술스택 및 개발 상세 내용
Python, Django, 
MySQL, Redis, 
Celery, RabbitMQ, 
React, 
Docker, Docker-Compose
Github Action
AWS

아키텍쳐




Ticketeer - (2024.06 - 2024.08)
프로젝트 개요
[link](https://github.com/watanka/concert-ticketing)
티켓티어는 콘서트 티켓 예매 프로젝트입니다. 티켓팅은 도메인 특성상, 단발성의 대용량 트래픽 처리가 필요합니다.
짧은 시간동안 대용량 트래픽이 몰리는 경우, auto-scaling을 통해 scale out하여 인프라적으로 처리하는 방법도 있지만, 백엔드 관점에서 처리도 가능합니다.
티켓팅을 위해 접속한 사용자들에게 순차적으로 접근할 수 있도록 토큰을 부여하고, 접속한 순서대로 서비스에 접근 권한을 부여하는 식으로 대기열을 구현하였습니다.
그리고, 여러 사용자가 접근함에 따라 생길 수 있는 경합 상황(race condition)을 예상하고, 분산락을 적용하여 정합성을 보장하였습니다.


기술스택 및 개발 상세 내용
기술 스택
Java, SpringBoot, MySQL, Redis, Spring Data JPA, JUnit, Mockito, Docker, AWS, Github Action
아키텍쳐
구현한 기능:

콘서트 및 콘서트 좌석 조회
콘서트 좌석예약
포인트 충전/조회
결제내역 조회
동시성 처리를 통한 데이터 정합성 보장
대기열 구성을 통한 트래픽 처리

### 대외활동
개발자 글쓰기 모임 글또
자격증
CKA(Certified Kubernetes Administrator) 2024.09 
SQLD - 2024.09 
AWS Cloud Practitioner - 2024.06 
빅데이터 분석 기사 2022.12  

프로젝트 이름
프로젝트 개요
프로젝트 소개 및 주요 기능
기술 스택 및 개발 상세 내용
어떤 문제를 해결했는가? 어떤 부분에서 기여했는가

트윈리더

여러 문서 유형(보험 청구서, 진료비 영수증, 견적서)에 대한 OCR 성능을 개선하는 업무 담당
Scene Text Detection 모델 실험 및 개발
OCR 서비스 개발
온프레미스 환경(폐쇄망)에 서비스 배포 더 빠르고 성능 좋은 STD 모델 개발 데이터 품질, 수량 추가 확보 모델 학습 실험 환경 개선 OCR 파싱 정보 계층화 시도
